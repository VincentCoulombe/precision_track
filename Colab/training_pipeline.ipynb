{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1bf36f",
   "metadata": {},
   "source": [
    "# Welcome to the PrecisionTrack Training and Testing Notebook.\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/VincentCoulombe/precision_track/main/assets/logo.png)\n",
    "\n",
    "### In this notebook, you will:\n",
    "- Train a PrecisionTracker on the MICE dataset.  \n",
    "- Test your newly trained PrecisionTracker.\n",
    "- Visualize pose-tracking results on unseen footage.\n",
    "\n",
    "**Note:**  \n",
    "To deploy, track and visualize your PrecisionTrack checkpoints, please refer to our [tutorials](https://github.com/VincentCoulombe/precision_track/tree/main) and [configuration documentation](https://github.com/VincentCoulombe/precision_track/tree/main/configs).\n",
    "\n",
    "\n",
    "### Before you begin\n",
    "Ensure your Colab runtime is connected to a GPU:\n",
    "\n",
    "1. Click on **Runtime** in the menu bar.  \n",
    "2. Select **Change runtime type**.  \n",
    "3. Set the interpreter to **Python 3**.  \n",
    "4. Under **Hardware accelerator**, select **GPU**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# First, determine if the machine is cuda accelerated (to determine which version of the virtual environment we are goind to build).\n",
    "\n",
    "try:\n",
    "    CUDA_ACCELERATED = subprocess.run(\"nvidia-smi\").returncode == 0\n",
    "except FileNotFoundError:\n",
    "    CUDA_ACCELERATED = False\n",
    "    print(\"Please follow the instructions in the cell above to CUDA-accelerate your instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Second, build PrecisionTrack's virtual environment.\n",
    "!git clone https://github.com/VincentCoulombe/precision_track.git\n",
    "%cd /content/precision_track/\n",
    "\n",
    "if CUDA_ACCELERATED:\n",
    "    !pip install torch==2.7.1 torchvision==0.22.1  --index-url https://download.pytorch.org/whl/cu128\n",
    "    !pip install -e .[cuda]\n",
    "else:\n",
    "    !pip install torch==2.7.1 torchvision==0.22.1  --index-url https://download.pytorch.org/whl/cpu\n",
    "    !pip install -e .[cpu]\n",
    "    \n",
    "!pip install gdown\n",
    "# NOTE: This took some time when I tried it (about 12 minutes). This is because Pytorch and PyCuda are both heavy, wheeled, depedencies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains a custom helper function for visualizing video on the browser.\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def to_h264(video_path: str) -> tuple:\n",
    "    \"\"\"Convert the video codec to a browser-friendly one.\"\"\"\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",\n",
    "            \"-i\",\n",
    "            video_path,\n",
    "            \"-c:v\",\n",
    "            \"libx264\",\n",
    "            \"-profile:v\",\n",
    "            \"baseline\",\n",
    "            \"-level\",\n",
    "            \"3.0\",\n",
    "            \"-pix_fmt\",\n",
    "            \"yuv420p\",\n",
    "            \"-movflags\",\n",
    "            \"+faststart\",\n",
    "            \"./visualization_h264.mp4\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "    mp4 = open(\"./visualization_h264.mp4\", \"rb\").read()\n",
    "    return \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd47cd0",
   "metadata": {},
   "source": [
    "### Dataset preparation\n",
    "\n",
    "We will **train and test on the MICE dataset**.  \n",
    "Before proceeding, we need to **download the dataset** and the relevant **Transfer learning checkpoint**.\n",
    "\n",
    "#### NOTE:\n",
    "If you would like to create and label your own dataset instead, please refer to our  \n",
    "[training workflow guide](https://github.com/VincentCoulombe/precision_track/tree/main).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ae82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /content/precision_track/checkpoints/\n",
    "%cd /content/precision_track/checkpoints/\n",
    "!gdown --id 1OEsczExkQ38pyyrEmH9To9ZTmGPRyaBj # The Animal Pose checkpoint (for transfer learning)\n",
    "\n",
    "!mkdir /content/datasets/MICE/\n",
    "%cd /content/datasets/MICE/\n",
    "!gdown --id 1swPZZxqF6L0wbEDY_EE-esG9GZNt42mU # The MICE dataset\n",
    "!unzip /content/datasets/MICE/pose-estimation.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac0bd8",
   "metadata": {},
   "source": [
    "### OPTIONNAL\n",
    "PrecisionTrack offers the ability to log your training runs using the [Weights & Biases (W&B)](https://wandb.ai/) MLOps tool.  \n",
    "\n",
    "By enabling this functionnality will allow PrecisionTrack to:\n",
    "\n",
    "- **Track experiments**: Log training hyperparameters, metrics, and outputs.  \n",
    "- **Visualize results**: Generate interactive plots and dashboards. Usefull for comparing training run.  \n",
    "- **Collaborate**: Share runs, reports, and insights with teammates.  \n",
    "- **Manage models**: Version control for datasets, models, and pipelines.\n",
    "\n",
    "To enable this functionnality, please refer to our [Weights & Biases guide](https://github.com/VincentCoulombe/precision_track/tree/main/configs/wandb). You will then be able to set `WANDB_ENABLED = True` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, change the settings to load the downloaded Animal Pose checkpoint.\n",
    "# NOTE: This step is done Programmatically here, but I encourage the users to do it manually instead (its way more intuitive). Please refer to our settings and workflow guides for more details.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from mmengine import Config\n",
    "\n",
    "SETTINGS_PATH = \"/content/precision_track/configs/settings/mice.py\"\n",
    "settings = Config.fromfile(SETTINGS_PATH)\n",
    "\n",
    "# Accessing the actual variables\n",
    "actual_training_ckpt_path = settings[\"training_checkpoint\"]\n",
    "\n",
    "# Updating the variables\n",
    "new_training_ckpt_path = os.path.join(\"/content/precision_track/checkpoints/\", \"model_ap.pth\")\n",
    "\n",
    "# OPTIONAL: If you followed our Weight & Biases guide, have a functionnal wandb.py file and want to log your training run results, change the following to 'True'.\n",
    "WANDB_ENABLED = False\n",
    "\n",
    "# OPTIONAL: I changed to batch size to not overflow the provided GPU's vRAM.\n",
    "NEW_BATCH_SIZE = 24\n",
    "\n",
    "file = Path(os.path.abspath(SETTINGS_PATH))\n",
    "text = file.read_text()\n",
    "text = text.replace(actual_training_ckpt_path, new_training_ckpt_path)\n",
    "text = text.replace(\"wandb_logging = False\", f\"wandb_logging = {WANDB_ENABLED}\")\n",
    "text = text.replace(\"batch_size = 38\", f\"batch_size={NEW_BATCH_SIZE}\")\n",
    "file.write_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c664654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, Train the network on the MICE dataset.\n",
    "# NOTE: this step will take a few hours. The process will finish after 300 epochs.\n",
    "# NOTE: If your instance is not CUDA-accelerated, do not bother running this step, it would take too long to complete.\n",
    "# NOTE: Our training engine is very verbose. This level of detail is intentional and helpful for debugging, though it may appear overwhelming at first. Do no worry, unless an exception is explicitly raised, the process is functioning as expected.\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, change the settings to load the newly trained checkpoint.\n",
    "\n",
    "SETTINGS_PATH = \"/content/precision_track/configs/settings/mice.py\"\n",
    "settings = Config.fromfile(SETTINGS_PATH)\n",
    "\n",
    "# Accessing the actual variables\n",
    "actual_testing_ckpt_path = settings[\"testing_checkpoint\"]\n",
    "actual_training_work_dir = settings[\"training_work_dir\"]\n",
    "\n",
    "# Updating the variables\n",
    "new_testing_ckpt_path = os.path.join(actual_training_work_dir, \"epoch_300.pth\")\n",
    "\n",
    "file = Path(os.path.abspath(SETTINGS_PATH))\n",
    "text = file.read_text()\n",
    "text = text.replace(actual_testing_ckpt_path, new_testing_ckpt_path)\n",
    "file.write_text(text)\n",
    "\n",
    "# Third, test the system's detection and pose-estimation capabilities.\n",
    "# NOTE: Here, you should obtain results similar to those reported in Figure 2e.\n",
    "# NOTE: Since the training process is stochastic, you will most likely not have the exact same results as those reported in the acticle. Although, you should obtain comparable results.\n",
    "!python test.py ../configs/tasks/testing_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ed70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth, test the system's tracking capabilities.\n",
    "# NOTE: Here, you should obtain results similar to those reported in Figure 5d\n",
    "# NOTE: Since the training process is stochastic, you will most likely not have the exact same results as those reported in the acticle. Although, you should obtain comparable results.\n",
    "!python test.py ../configs/tasks/testing_tracking.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd919da",
   "metadata": {},
   "source": [
    "### Tracking using your newly trained PrecisionTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3797f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the tracking configuration points towards our current model (maybe redundant, but necessary to prevent futur changes to break this cell)\n",
    "file = Path(os.path.abspath(\"/content/precision_track/configs/tasks/tracking.py\"))\n",
    "text = file.read_text()\n",
    "text = text.replace(\"../models/yolox-pose.py\", \"../models/rtmdet-pose.py\")\n",
    "text = text.replace(\"with_action_recognition = True\", \"with_action_recognition = False\")\n",
    "file.write_text(text)\n",
    "\n",
    "#Fifth, track using our current checkpoint.\n",
    "#NOTE: The logger will print the confirmation that you are tracking using the newly trained checkpoint (it will print the path to the currently used checkpoint).\n",
    "!python track.py /content/datasets/MICE/pose-estimation/benchmark/data/20mice.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth, generate and display the visualization.\n",
    "!python ./visualize.py /content/datasets/MICE/pose-estimation/benchmark/data/20mice.avi /content/datasets/MICE/pose-estimation/benchmark/data/20mice_visualization.mp4\n",
    "\n",
    "# Display.\n",
    "data_url = to_h264(\"/content/datasets/MICE/pose-estimation/benchmark/data/20mice_visualization.mp4\")\n",
    "\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "<video width=800 controls>\n",
    "    <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
