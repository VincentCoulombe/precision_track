{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Environment Setup for DeepLabCut Evaluation\n",
    "\n",
    "## Introduction\n",
    "This notebook is dedicated to evaluating the inference performance of DeepLabCut in terms of both tracking quality and latency. Below are the steps to set up the necessary environment on Ubuntu 22.04.\n",
    "\n",
    "## Installation\n",
    "\n",
    "### Create Conda Environment\n",
    "To begin, create a Conda environment named `DLC` with the necessary packages. Run the following commands in your terminal:\n",
    "\n",
    "```bash\n",
    "conda create -n DLC python==3.10\n",
    "conda activate DLC\n",
    "pip install deeplabcut==3.0.0rc7\n",
    "```\n",
    "\n",
    "### Additional Libraries\n",
    "After setting up the Conda environment, install the following Python libraries using pip:\n",
    "\n",
    "- **tqdm** for progress bars:\n",
    "  ```bash\n",
    "  pip install tqdm==4.66.4\n",
    "  ```\n",
    "- **tabulate** for table creation and formatting:\n",
    "  ```bash\n",
    "  pip install tabulate==0.9.0\n",
    "  ```\n",
    "- **motmetrics** for computing metrics for object tracking:\n",
    "  ```bash\n",
    "  pip install motmetrics==1.4.0\n",
    "  ```\n",
    "- **mmengine** for the registry :\n",
    "  ```bash\n",
    "  pip install mmengine-lite\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "from mmengine.config import Config\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from utils.downsize_video import downsize_video\n",
    "from utils.dlc300_inference_w_timer import analyze_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the DLC config\n",
    "\n",
    "You need to make sure you have a valid DLC checkpoint trained on MICE. For more informations, please visit DLC's documentation: https://deeplabcut.github.io/DeepLabCut/docs/quick-start/tutorial_maDLC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"../../configs/deeplabcut/evaluation.py\"\n",
    "cfg = Config.fromfile(cfg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Comparison Standards\n",
    "\n",
    "For a fair latency comparison, it is crucial that all algorithms perform inference on images of the same resolution. This standardization ensures that any observed differences in processing speed are due to the algorithms themselves, not variations in image size or quality.\n",
    "\n",
    "For this reason, we need to format the video so its resolution matches those used for the PrecisionTrack and SLEAP evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaling video from 1536x1536 to 640x640\n"
     ]
    }
   ],
   "source": [
    "videos = []\n",
    "for video in cfg.videos:\n",
    "    ori_video = cv2.VideoCapture(video)\n",
    "    ori_width = int(ori_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    ori_height = int(ori_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    if ori_height != cfg.img_size[0] or ori_width != cfg.img_size[1]:\n",
    "        print(f\"Rescaling video from {ori_height}x{ori_width} to {cfg.img_size[0]}x{cfg.img_size[1]}\")\n",
    "        split = os.path.splitext(video)\n",
    "        rescaled_video_path = f\"{split[0]}_{cfg.img_size[0]}x{cfg.img_size[1]}{split[1]}\"\n",
    "        video = downsize_video(\n",
    "            video,\n",
    "            rescaled_video_path,\n",
    "            height=cfg.img_size[0],\n",
    "            width=cfg.img_size[1],\n",
    "        )\n",
    "    videos.append(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-30000 for model /home/vincent/Documents/precision_track/precision_track/evaluation/comparisons/ckpts/deeplabcut/dlc-models/iteration-0/miceNov03-trainset80shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/mambaforge/envs/DLC/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating extracting of PAFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 08:55:35.632243: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-12 08:55:35.633608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-12 08:55:35.634767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-12 08:55:35.635904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-12 08:55:35.637048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-12 08:55:35.638137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13655 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  ../../assets/20mice_640x640.avi\n",
      "Loading  ../../assets/20mice_640x640.avi\n",
      "Duration of video [s]:  52.54 , recorded with  28.0 fps!\n",
      "Overall # of frames:  1471  found with (before cropping) frame dimensions:  640 640\n",
      "Starting to extract posture from the video(s) with batchsize: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1471/1471 [00:21<00:00, 68.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Analyzed. Saving results in ../../assets...\n",
      "Using snapshot-30000 for model /home/vincent/Documents/precision_track/precision_track/evaluation/comparisons/ckpts/deeplabcut/dlc-models/iteration-0/miceNov03-trainset80shuffle1\n",
      "Processing...  ../../assets/20mice_640x640.avi\n",
      "Analyzing ../../assets/20mice_640x640DLC_dlcrnetms5_miceNov03shuffle1_30000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1471/1471 [00:03<00:00, 376.81it/s]\n",
      "1471it [00:02, 529.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created (i.e., under the hood deeplabcut.convert_detections2tracklets was run). Now you can 'refine_tracklets' in the GUI, or run 'deeplabcut.stitch_tracklets'.\n",
      "Processing...  ../../assets/20mice_640x640.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:00<00:00, 484.25it/s]\n",
      "/home/vincent/mambaforge/envs/DLC/lib/python3.10/site-packages/deeplabcut/refine_training_dataset/stitch.py:939: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  df.to_hdf(output_name, \"tracks\", format=\"table\", mode=\"w\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TRACKING RESULTS TO: ../../assets/20mice_640x640DLC_dlcrnetms5_miceNov03shuffle1_30000_el.h5\n",
      "\n",
      "| FPS    |   Inference Time (s) |\n",
      "|--------|----------------------|\n",
      "| Mean   |               42.089 |\n",
      "| Std    |                0.000 |\n",
      "| Min    |               42.089 |\n",
      "| Median |               42.089 |\n",
      "| Max    |               42.089 |\n",
      "../../assets/20mice_640x640.avi analysis ran at 42.089 FPS.\n"
     ]
    }
   ],
   "source": [
    "video = rescaled_video_path\n",
    "\n",
    "path_to_dlc_cfg = cfg.config\n",
    "batch_size = cfg.batch_size\n",
    "n_tracks = cfg.n_tracks\n",
    "save_as_csv = cfg.save_as_csv\n",
    "shuffle = 1\n",
    "\n",
    "fps = analyze_videos(\n",
    "    path_to_dlc_cfg, videos=[video], shuffle=shuffle, gputouse=0, batchsize=batch_size, n_tracks=n_tracks, save_as_csv=save_as_csv, auto_track=True\n",
    ")[1][0]\n",
    "print(f\"{video} analysis ran at {fps:.3f} FPS.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
