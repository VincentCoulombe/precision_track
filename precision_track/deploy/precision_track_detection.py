# Copyright (c) OpenMMLab. All rights reserved.

# Modifications made by:
# Copyright (c) Vincent Coulombe

# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.


import json
import os.path as osp
from copy import deepcopy
from typing import Callable, Dict, List, Optional, Union

import numpy as np
import torch
from mmengine.config import Config
from mmengine.registry import DefaultScope, Registry

from precision_track.registry import CODEBASE, DATASETS, MODELS
from precision_track.utils import Codebase, Task, get_codebase, get_device, get_task_type, load_checkpoint


def load_metainfo(model_cfg: Config):
    for dataloader_name in ["test_dataloader", "val_dataloader", "train_dataloader"]:
        if dataloader_name not in model_cfg:
            continue
        dataset_cfg = model_cfg[dataloader_name].dataset
        dataset = DATASETS.build(dataset_cfg)
        if hasattr(dataset, "_load_metainfo") and isinstance(dataset._load_metainfo, Callable):
            meta = dataset._load_metainfo(dataset_cfg.get("metainfo", None))
            if meta is not None:
                return meta
    return None


PT_TASK = Registry("pt_tasks")


@CODEBASE.register_module(Codebase.PRECISION_TRACK.value)
class PrecisionTrack:
    """mmpose codebase class."""

    task_registry = PT_TASK

    @classmethod
    def get_task_class(cls, task: Task):
        """Get the task processors class according to the task type.

        Args:
            task (Task): The task enumeration.

        Returns:
            type: The task processor class.
        """
        return cls.task_registry.module_dict[task.value]

    @classmethod
    def build_task_processor(cls, model_cfg: Config, deploy_cfg: Config, device: str, is_mart: bool = False):
        """The interface to build the task processors of the codebase.

        Args:
            model_cfg (str | Config): Model config file.
            deploy_cfg (str | Config): Deployment config file.
            device (str): A string specifying device type.

        Returns:
            BaseTask: A task processor.
        """
        if is_mart:
            task = "MARTActionRecognition"
        else:
            task = get_task_type(deploy_cfg).value
        return cls.task_registry.build(dict(type=task, model_cfg=model_cfg, deploy_cfg=deploy_cfg, device=device))


@PT_TASK.register_module(Task.PRECISION_TRACK_DETECTION.value)
class PrecisionTrackDetection:
    def __init__(self, model_cfg: Config, deploy_cfg: Config, device: str, experiment_name: str = "BaseTask"):

        self.model_cfg = model_cfg
        self.deploy_cfg = deploy_cfg
        self.device = get_device() if device == "auto" else device
        self.preprocessor = MODELS.build(self.model_cfg.data_preprocessor)
        self.codebase = get_codebase(deploy_cfg)
        self.experiment_name = experiment_name

        if not DefaultScope.check_instance_created(self.experiment_name):
            self.scope = DefaultScope.get_instance(self.experiment_name, scope_name=str(self.model_cfg.get("default_scope")))
        else:
            self.scope = DefaultScope.get_instance(self.experiment_name)

    @classmethod
    def build_task_processor(cls, model_cfg: Config, deploy_cfg: Config, device: str):
        """The interface to build the task processors of the codebase.

        Args:
            model_cfg (str | Config): Model config file.
            deploy_cfg (str | Config): Deployment config file.
            device (str): A string specifying device type.

        Returns:
            BaseTask: A task processor.
        """
        task = get_task_type(deploy_cfg)
        return cls.task_registry.build(dict(type=task.value, model_cfg=model_cfg, deploy_cfg=deploy_cfg, device=device))

    def create_input(
        self,
        imgs: List[Union[str, np.ndarray]],
        **kwargs,
    ) -> Dict:
        """Create input for pose detection.

        Args:
            imgs (Any): Input image(s), accepted data type are ``str``,
                ``np.ndarray``.
        """
        return self.preprocessor(dict(inputs=imgs, data_samples=[i for i in range(len(imgs))]))

    def build_pytorch_model(self, model_checkpoint: Optional[str] = None, cfg_options: Optional[Dict] = None, **kwargs) -> torch.nn.Module:
        """Initialize torch model.

        Args:
            model_checkpoint (str): The checkpoint file of torch model,
                defaults to `None`.
            cfg_options (dict): Optional config key-pair parameters.

        Returns:
            nn.Module: An initialized torch model generated by other OpenMMLab
                codebases.
        """
        from mmengine.model import revert_sync_batchnorm
        from mmengine.registry import MODELS

        model = deepcopy(self.model_cfg)
        model.pop("pretrained", None)
        preprocess_cfg = deepcopy(self.model_cfg.get("preprocess_cfg", {}))
        preprocess_cfg.update(deepcopy(self.model_cfg.get("data_preprocessor", {})))
        model.setdefault("data_preprocessor", preprocess_cfg)
        model = MODELS.build(model)
        if model_checkpoint is not None:
            load_checkpoint(model, model_checkpoint, map_location=self.device)
            ckpt_dir = osp.dirname(model_checkpoint)
            hyperparams_path = osp.join(ckpt_dir, "hyperparameters.json")
            if osp.exists(hyperparams_path):
                with open(hyperparams_path, "r") as f:
                    try:
                        hyperparams = json.load(f)
                    except json.JSONDecodeError:
                        hyperparams = {}
                if hasattr(model, "head") and hasattr(model.head, "temperature"):
                    model.head.temperature = hyperparams.get("calibrated_temperature", 1)

        model = revert_sync_batchnorm(model)
        if hasattr(model, "backbone") and hasattr(model.backbone, "switch_to_deploy"):
            model.backbone.switch_to_deploy()

        if hasattr(model, "switch_to_deploy") and callable(model.switch_to_deploy):
            model.switch_to_deploy()

        del model.data_preprocessor
        model = model.to(self.device)
        model.eval()
        return model


@PT_TASK.register_module(Task.MART_ACTION_RECOGNITION.value)
class MARTActionRecognition(PrecisionTrackDetection):
    def __init__(self, model_cfg: Config, deploy_cfg: Config, device: str, experiment_name: str = "BaseTask"):

        self.model_cfg = model_cfg
        self.deploy_cfg = deploy_cfg
        self.device = device
        self.preprocessor = MODELS.build(self.model_cfg.data_preprocessor)
        self.codebase = get_codebase(deploy_cfg)
        self.experiment_name = experiment_name

        if not DefaultScope.check_instance_created(self.experiment_name):
            self.scope = DefaultScope.get_instance(self.experiment_name, scope_name=str(self.model_cfg.get("default_scope")))
        else:
            self.scope = DefaultScope.get_instance(self.experiment_name)

    def create_input(
        self,
        tracking_output: dict,
        **kwargs,
    ) -> Dict:
        return self.preprocessor(dict(data_samples=[tracking_output]))
